{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/X-T-E-R/GPT-SoVITS-Inference/blob/stable/colab_webui.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_o6a8GS2lWQM"
      },
      "source": [
        "环境配置 Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9b7iFV3dm1f"
      },
      "outputs": [],
      "source": [
        "# @title Clone or Update the repository 克隆或更新存储库\n",
        "%cd /content/\n",
        "!git clone https://github.com/X-T-E-R/GPT-SoVITS-Inference.git\n",
        "\n",
        "# Make sure to pull the latest changes from the repository\n",
        "%cd /content/GPT-SoVITS-Inference\n",
        "!git stash\n",
        "!git pull https://github.com/X-T-E-R/GPT-SoVITS-Inference.git stable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title Install the required dependencies 安装所需的依赖项\n",
        "!apt-get update && apt-get install -y --no-install-recommends tzdata ffmpeg libsox-dev parallel aria2 git git-lfs && git lfs install\n",
        "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "%pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0NgxXg5sjv7z"
      },
      "outputs": [],
      "source": [
        "# @title Download pretrained models 下载预训练模型\n",
        "!mkdir -p /content/GPT-SoVITS-Inference/GPT_SoVITS/pretrained_models\n",
        "\n",
        "%cd /content/GPT-SoVITS-Inference/GPT_SoVITS/pretrained_models\n",
        "!git clone https://huggingface.co/lj1995/GPT-SoVITS\n",
        "\n",
        "!git config core.sparseCheckout true\n",
        "!mv /content/GPT-SoVITS-Inference/GPT_SoVITS/pretrained_models/GPT-SoVITS/* /content/GPT-SoVITS-Inference/GPT_SoVITS/pretrained_models/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "设置 Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# settings\n",
        "%cd /content/GPT-SoVITS-Inference\n",
        "import json\n",
        "config = {}\n",
        "try:\n",
        "    with open(\"Inference/config.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "        config = json.load(f)\n",
        "except FileNotFoundError:\n",
        "    raise FileNotFoundError(\"config.json not found, please check the file path.\")\n",
        "\n",
        "# 如果你想看中文，请设置为 \"zh-CN\"\n",
        "config[\"locale\"] = \"en-US\" #@param {type: \"string\"}\n",
        "config[\"is_share\"] = \"true\"\n",
        "config[\"models_path\"] = \"trained\" #@param {type: \"string\"}\n",
        "\n",
        "try:\n",
        "    with open(\"Inference/config.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(config, f, ensure_ascii=False, indent=4)\n",
        "except FileNotFoundError:\n",
        "    raise FileNotFoundError(\"config.json not found, please check the file path.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "下载模型/手动导入 Download or manually put models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%cd /content/GPT-SoVITS-Inference\n",
        "#@title Import model 导入模型 (HuggingFace)\n",
        "\n",
        "# put your character folder in trained/\n",
        "# or use the code below to download the HuggingFace model\n",
        "# please check if the zip contains the model files and a audio_file named by its content\n",
        "# if not, please modify the folder manually in trained/ \n",
        "\n",
        "import requests\n",
        "import zipfile\n",
        "import shutil\n",
        "import os\n",
        "import urllib.parse\n",
        "\n",
        "\n",
        "hf_links = [''] * 10\n",
        "\n",
        "# special thanks to baicai1145 for providing the example model(and its copyright belongs to the Mihoyo)\n",
        "# copy the link from the download button on the model page\n",
        "hf_links[0] = 'https://huggingface.co/baicai1145/GPT-SoVITS-STAR/resolve/main/%E9%93%B6%E7%8B%BC.zip?download=true' #@param {type: \"string\"}\n",
        "hf_links[1] = 'https://huggingface.co/baicai1145/GPT-SoVITS-STAR/resolve/main/%E9%9D%92%E9%9B%80.zip?download=true' #@param {type: \"string\"}\n",
        "\n",
        "for i, hf_link in enumerate(hf_links):\n",
        "    if hf_link == '':\n",
        "        continue\n",
        "    # get the name of the character folder, or you can set it manually\n",
        "    character_name = urllib.parse.unquote(os.path.basename(hf_link).rsplit('.', 1)[0])\n",
        "\n",
        "    print(f'Downloading {character_name}...')\n",
        "\n",
        "    output_path = os.path.join('trained', character_name)\n",
        "    os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "    zip_file_path = os.path.join(output_path, 'file.zip')\n",
        "\n",
        "    # download the zip file\n",
        "    response = requests.get(hf_link)\n",
        "    with open(zip_file_path, 'wb') as file:\n",
        "        file.write(response.content)\n",
        "\n",
        "    # extract the zip file\n",
        "    import zipfile\n",
        "\n",
        "    def get_decoder(file_name: str):\n",
        "        try:\n",
        "            return file_name.encode('cp437').decode('gbk')\n",
        "        except:\n",
        "            return file_name\n",
        "\n",
        "    print(f'Extracting {character_name}...')\n",
        "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "        for file_info in zip_ref.infolist():\n",
        "            # 解码并重新编码文件名\n",
        "            encoded_file_name = get_decoder(file_info.filename)\n",
        "            new_path = os.path.join(output_path, encoded_file_name)\n",
        "            source = zip_ref.open(file_info.filename)\n",
        "            # 判断f是否是目录，目录的结尾是'/'或'\\'\n",
        "            if encoded_file_name[-1] not in ['\\\\','/']:\n",
        "                with open(new_path,'wb') as file:\n",
        "                    file.write(zip_ref.read(file_info.filename))\n",
        "                    file.close()\n",
        "            else:\n",
        "                os.makedirs(new_path, exist_ok=True)\n",
        "    print(f'{character_name} downloaded and extracted successfully!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "GSVI，启动！ Launch Webui"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4oRGUzkrk8C7"
      },
      "outputs": [],
      "source": [
        "# @title launch app 启动app\n",
        "# special thanks to @rc4 \n",
        "%cd /content/GPT-SoVITS-Inference/\n",
        "import codecs\n",
        "abc = codecs.decode(\"ncc.cl\", \"rot_13\")\n",
        "# \"ncc\" stands for \"app\", a small trick to avoid the program from being killed\n",
        "!/usr/local/bin/python {abc} "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title launch Model Manager 启动模型管理器\n",
        "%cd /content/GPT-SoVITS-Inference/\n",
        "import codecs\n",
        "abc = codecs.decode(\"Vasrerapr/fep/Punenpgre_Znantre.cl\", \"rot_13\")\n",
        "# \"Vasrerapr/fep/Punenpgre_Znantre\" stands for \"Inference\\src\\Character_Manager\", a small trick to avoid the program from being killed\n",
        "!/usr/local/bin/python {abc} "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
